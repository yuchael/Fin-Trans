import requests
import os
import sys
import pandas as pd
import logging
import re
import io  # [í•„ìˆ˜] ë¬¸ìì—´ì„ íŒŒì¼ì²˜ëŸ¼ ë‹¤ë£¨ê¸° ìœ„í•´ í•„ìš”
from datetime import datetime
from dotenv import load_dotenv

# utils í´ë”ì˜ handle_sql.pyì—ì„œ í•¨ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
try:
    from utils.handle_sql import execute_query, execute_many
except ImportError:
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from utils.handle_sql import execute_query, execute_many

load_dotenv()

# --- [ë¡œê¹… ì„¤ì •] ---
def setup_logging():
    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, "execution.log")

    logging.basicConfig(
        level=logging.INFO,
        format="[%(asctime)s] %(levelname)s: %(message)s",
        handlers=[
            logging.FileHandler(log_file, mode='w', encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )

def fetch_naver_rates():
    """ë„¤ì´ë²„ ê¸ˆìœµ í™˜ìœ¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. (íŒŒì¼ ì €ì¥ ì—†ì´ ë©”ëª¨ë¦¬ ì²˜ë¦¬)"""
    url = "https://finance.naver.com/marketindex/exchangeList.naver"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }

    logging.info("ğŸ”„ ë„¤ì´ë²„ ê¸ˆìœµ ë°ì´í„° ìš”ì²­ ì¤‘...")

    try:
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            # 1. ì¸ì½”ë”© ì„¤ì • (ë„¤ì´ë²„ ê¸ˆìœµì€ cp949/euc-kr ì‚¬ìš©)
            response.encoding = 'cp949'
            
            # 2. ë°ì´í„° íŒŒì‹± (íŒŒì¼ ì €ì¥ ë¡œì§ ì œê±°ë¨)
            try:
                # [ì¤‘ìš”] response.textë¥¼ ë°”ë¡œ read_htmlì— ë„£ìœ¼ë©´ íŒŒì¼ ê²½ë¡œë¡œ ì°©ê°í•  ìˆ˜ ìˆì–´ io.StringIO ì‚¬ìš©
                html_io = io.StringIO(response.text)
                
                # header=1: ë‘ ë²ˆì§¸ ì¤„(ì‚¬ì‹¤ ë•Œ, íŒŒì‹¤ ë•Œ ë“±)ì„ í—¤ë”ë¡œ ì¸ì‹ ì‹œë„
                dfs = pd.read_html(html_io, header=1)
                
                if dfs:
                    df = dfs[0]
                    # ë„¤ì´ë²„ ê¸ˆìœµ í™˜ìœ¨í‘œ êµ¬ì¡° ê¸°ë°˜ ì¸ë±ì‹± (í™”ë©´ì— ë³´ì´ëŠ” ìˆœì„œëŒ€ë¡œ)
                    # col 0: í†µí™”ëª…
                    # col 1: ë§¤ë§¤ê¸°ì¤€ìœ¨
                    # col 4: ì†¡ê¸ˆ ë³´ë‚´ì‹¤ ë•Œ (TTS)
                    # col 5: ì†¡ê¸ˆ ë°›ìœ¼ì‹¤ ë•Œ (TTB)
                    
                    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ìœ„ì¹˜(index)ë¡œ ì¶”ì¶œí•˜ì—¬ ë³µì‚¬
                    target_df = df.iloc[:, [0, 1, 4, 5]].copy()
                    
                    # ì»¬ëŸ¼ëª… ì¬ì„¤ì • (DB ì»¬ëŸ¼ê³¼ ë§¤í•‘í•˜ê¸° ì¢‹ê²Œ ì§ê´€ì ìœ¼ë¡œ ë³€ê²½)
                    target_df.columns = ['í†µí™”ëª…', 'ë§¤ë§¤ê¸°ì¤€ìœ¨', 'ì „ì‹ í™˜_ë³´ë‚´ì‹¤ë•Œ', 'ì „ì‹ í™˜_ë°›ìœ¼ì‹¤ë•Œ']
                    
                    now = datetime.now()
                    date_str = now.strftime("%Y%m%d")
                    
                    logging.info(f"âœ… íŒŒì‹± ì„±ê³µ! ë°ì´í„° {len(target_df)}ê±´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                    return target_df, date_str
                else:
                    logging.warning("âš ï¸ HTML í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return None, None

            except ImportError:
                logging.error("âŒ 'lxml' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. í„°ë¯¸ë„ì— 'pip install lxml'ì„ ì…ë ¥í•˜ì„¸ìš”.")
                return None, None
            except Exception as parse_error:
                logging.error(f"âš ï¸ íŒŒì‹± ì¤‘ ì—ëŸ¬ ë°œìƒ: {parse_error}")
                return None, None
        else:
            logging.error(f"âŒ ìš”ì²­ ì‹¤íŒ¨ (Status: {response.status_code})")
            return None, None

    except Exception as e:
        logging.error(f"âŒ í¬ë¡¤ë§ ì—ëŸ¬: {e}")
        return None, None

def process_and_save(df, date_str):
    """ë°ì´í„° ì „ì²˜ë¦¬ ë° ì €ì¥ (CSV + MySQL)"""
    if df is None or df.empty:
        return

    # ì „ì²˜ë¦¬ ì‘ì—…ì„ ìœ„í•´ ë³µì‚¬
    df = df.copy()

    # 1. í†µí™”ëª… ì •ì œ (HTMLì˜ ê³µë°±/ê°œí–‰ë¬¸ì ì œê±°)
    df['êµ­ê°€/í†µí™”ëª…'] = df['í†µí™”ëª…'].astype(str).str.strip()
    
    # í†µí™”ì½”ë“œ ì¶”ì¶œ (ì˜ˆ: "ë¯¸êµ­ USD" -> "USD", "ì¼ë³¸ JPY (100ì—”)" -> "JPY")
    def extract_code(text):
        match = re.search(r'([A-Z]{3})', text)
        return match.group(1) if match else 'KRW'
    
    df['í†µí™”ì½”ë“œ'] = df['êµ­ê°€/í†µí™”ëª…'].apply(extract_code)

    # 2. ìˆ«ì ë°ì´í„° ì „ì²˜ë¦¬ (ì½¤ë§ˆ ì œê±°, N/A ì²˜ë¦¬)
    target_cols = ['ë§¤ë§¤ê¸°ì¤€ìœ¨', 'ì „ì‹ í™˜_ë³´ë‚´ì‹¤ë•Œ', 'ì „ì‹ í™˜_ë°›ìœ¼ì‹¤ë•Œ']
    
    for col in target_cols:
        # ë¬¸ìì—´ ë³€í™˜ -> ì½¤ë§ˆ ì œê±° -> ìˆ«ìë¡œ ë³€í™˜ (ì‹¤íŒ¨ì‹œ NaN) -> NaNì€ 0ìœ¼ë¡œ ëŒ€ì²´
        df[col] = df[col].astype(str).str.replace(",", "").str.strip()
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    # 3. ê¸°ì¤€ì¼ì ì¶”ê°€
    df['ê¸°ì¤€ì¼ì'] = date_str

    # 4. ì €ì¥í•  ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
    final_columns = ['ê¸°ì¤€ì¼ì', 'í†µí™”ì½”ë“œ', 'êµ­ê°€/í†µí™”ëª…', 'ë§¤ë§¤ê¸°ì¤€ìœ¨', 'ì „ì‹ í™˜_ë°›ìœ¼ì‹¤ë•Œ', 'ì „ì‹ í™˜_ë³´ë‚´ì‹¤ë•Œ']
    df = df[final_columns]

    # --- CSV ì €ì¥ ---
    save_dir = "data"
    os.makedirs(save_dir, exist_ok=True)
    csv_filename = os.path.join(save_dir, "exchange_rates.csv")
    df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
    logging.info(f"ğŸ’¾ CSV ì €ì¥ ì™„ë£Œ: {csv_filename}")
    
    # --- MySQL ì €ì¥ ---
    save_to_mysql(df, date_str)

def save_to_mysql(df, date_str):
    """MySQL ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"

    try:
        logging.info(f"ğŸ”Œ MySQL ì €ì¥ ì‹œì‘ (ê¸°ì¤€ì¼: {formatted_date})")
        
        # 1. ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì¤‘ë³µ ë°©ì§€)
        delete_sql = "DELETE FROM exchange_rates"
        execute_query(delete_sql, (formatted_date,))
        
        # 2. ìƒˆ ë°ì´í„° ì‚½ì…
        insert_sql = """
        INSERT INTO exchange_rates 
        (reference_date, currency_code, currency_name, deal_bas_r, ttb, tts)
        VALUES (%s, %s, %s, %s, %s, %s)
        """
        
        data_list = []
        for _, row in df.iterrows():
            data_list.append((
                formatted_date,
                row['í†µí™”ì½”ë“œ'],
                row['êµ­ê°€/í†µí™”ëª…'],
                row['ë§¤ë§¤ê¸°ì¤€ìœ¨'],
                row['ì „ì‹ í™˜_ë°›ìœ¼ì‹¤ë•Œ'],
                row['ì „ì‹ í™˜_ë³´ë‚´ì‹¤ë•Œ']
            ))
        
        inserted_count = execute_many(insert_sql, data_list)
        logging.info(f"ğŸ“¥ DB ì €ì¥ ì™„ë£Œ: {inserted_count}ê±´")

    except Exception as e:
        logging.error(f"âŒ DB ì €ì¥ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    setup_logging()
    
    # SSL ê²½ê³  ë¬´ì‹œ (í•„ìš”ì‹œ ì‚¬ìš©)
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

    logging.info("ğŸš€ í™˜ìœ¨ ì •ë³´ ì—…ë°ì´íŠ¸ ì‹œì‘...")
    
    rates_data, rates_date = fetch_naver_rates()
    
    if rates_data is not None:
        process_and_save(rates_data, rates_date)
        logging.info("ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        logging.warning("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
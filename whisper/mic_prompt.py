import os
import speech_recognition as sr
from openai import OpenAI
from dotenv import load_dotenv  # ì¶”ê°€ëœ ë¶€ë¶„
import io

# 1. .env íŒŒì¼ ë¡œë“œ
# ì´ í•¨ìˆ˜ê°€ ì‹¤í–‰ë˜ë©´ .env íŒŒì¼ì˜ ë‚´ìš©ì´ í™˜ê²½ ë³€ìˆ˜ë¡œ ë“±ë¡ë©ë‹ˆë‹¤.
load_dotenv()

# 2. í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
api_key = os.getenv("OPENAI_API_KEY")

# í‚¤ê°€ ì œëŒ€ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸ (ë””ë²„ê¹…ìš©)
if not api_key:
    raise ValueError("âŒ .env íŒŒì¼ì—ì„œ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = OpenAI(api_key=api_key)

def listen_from_mic():
    """
    ë§ˆì´í¬ë¡œë¶€í„° ìŒì„±ì„ ë“£ê³  ì„ì‹œ wav íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    """
    r = sr.Recognizer()
    
    with sr.Microphone() as source:
        print("ğŸ¤ ë§ì”€í•´ ì£¼ì„¸ìš” (ë“£ê³  ìˆìŠµë‹ˆë‹¤...)")
        
        # ë°°ê²½ ì†ŒìŒ ìˆ˜ì¤€ì„ ì¡°ì •í•˜ì—¬ ì •í™•ë„ í–¥ìƒ
        r.adjust_for_ambient_noise(source)
        
        try:
            # ìŒì„± ê°ì§€ ë° ë…¹ìŒ (íƒ€ì„ì•„ì›ƒ ì„¤ì • ì¶”ê°€: 5ì´ˆ ë™ì•ˆ ë§ ì—†ìœ¼ë©´ ì¢…ë£Œ)
            audio = r.listen(source, timeout=5, phrase_time_limit=10)
            print("âœ… ë…¹ìŒ ì™„ë£Œ! ë³€í™˜ ì¤‘...")
            
            # Whisper APIëŠ” íŒŒì¼ í˜•íƒœë¥¼ ìš”êµ¬í•˜ë¯€ë¡œ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            filename = "my_voice.wav"
            with open(filename, "wb") as f:
                f.write(audio.get_wav_data())
                
            return filename
        except sr.WaitTimeoutError:
            print("â³ ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

def transcribe_audio(filename):
    """
    ì €ì¥ëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ OpenAI Whisper APIë¡œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    if not filename: return None
    
    try:
        with open(filename, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1", 
                file=audio_file
                # language="ko" # í•„ìš” ì‹œ ì–¸ì–´ ê°•ì œ ì„¤ì • ê°€ëŠ¥
            )
        return transcript.text
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ (STT): {e}")
        return None

def transcribe_audio_bytes(audio_bytes):
    """
    ë¸Œë¼ìš°ì €ì—ì„œ ë„˜ì–´ì˜¨ ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ Whisperë¡œ ë³€í™˜
    """
    if not audio_bytes: 
        return None
    
    try:
        # OpenAI APIëŠ” íŒŒì¼ ê°ì²´ í˜•íƒœ(name ì†ì„± í•„ìš”)ë¥¼ ì›í•˜ë¯€ë¡œ BytesIO ë˜í•‘
        audio_file = io.BytesIO(audio_bytes)
        audio_file.name = "voice.wav"  # ê°€ìƒì˜ íŒŒì¼ëª… ì§€ì • (í•„ìˆ˜)

        transcript = client.audio.transcriptions.create(
            model="whisper-1", 
            file=audio_file,
            #language="ko" # í•œêµ­ì–´ ë³´ì •
        )
        return transcript.text
    except Exception as e:
        print(f"STT Error: {e}")
        return None

def ask_llm(text):
    """
    ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¥¼ LLM(GPT)ì—ê²Œ ë³´ë‚´ê³  ë‹µë³€ì„ ë°›ëŠ” í•¨ìˆ˜
    """
    try:
        with open("prompt/mic_system_prompt.md", "r", encoding="utf-8") as f:
                system_prompt_content = f.read()
            

        # 2. API í˜¸ì¶œì— ì ìš©
        response = client.chat.completions.create(
            model="gpt-4o-mini", 
            messages=[
                {
                    "role": "system", 
                    "content": system_prompt_content
                },
                {
                    "role": "user", 
                    "content": text
                }
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ (LLM): {e}")
        return None



# --- ë©”ì¸ ì‹¤í–‰ íë¦„ ---
if __name__ == "__main__":
    retry_mic = False  # ìŒì„± ì¸ì‹ ìë™ ì¬ì‹œë„ë¥¼ ì œì–´í•  ìƒíƒœ ë³€ìˆ˜ ì¶”ê°€

    while True:
        # 1. ì…ë ¥ ë°©ì‹ ì„ íƒ
        if retry_mic:
            # LLMì´ ëª¨ë¥¸ë‹¤ê³  ë‹µë³€í•´ì„œ ì§ˆë¬¸ ë‹¨ê³„ ì—†ì´ ìë™ìœ¼ë¡œ ìŒì„± ì¸ì‹ ì‹œì‘
            choice = 'm'
            retry_mic = False  # ë‹¤ìŒ ë£¨í”„ë¥¼ ìœ„í•´ í”Œë˜ê·¸ ì´ˆê¸°í™”
            print("\nğŸ”„ LLMì´ ë‹µë³€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ìŒì„± ì¸ì‹ì„ ë‹¤ì‹œ ì‹œì‘í•©ë‹ˆë‹¤.")
        else:
            # ì¼ë°˜ì ì¸ ê²½ìš°: ì‚¬ìš©ìì—ê²Œ ì…ë ¥ ë°©ì‹ ì„ íƒ ìš”ì²­
            choice = input("\nâŒ¨ï¸ í…ìŠ¤íŠ¸ ì…ë ¥ì€ 't', ğŸ¤ ìŒì„± ì…ë ¥ì€ 'm', ì¢…ë£Œí•˜ë ¤ë©´ 'q'ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”: ").strip().lower()

        if choice == 'q' or choice == 'ì¢…ë£Œ':
            print("ğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # [A] í…ìŠ¤íŠ¸ ì…ë ¥ ë°©ì‹
        if choice == 't':
            user_prompt = input("ğŸ’¬ ì§ˆë¬¸ì„ íƒ€ì´í•‘í•´ ì£¼ì„¸ìš”: ").strip()
            
            if not user_prompt:
                print("âš ï¸ ì•„ë¬´ê²ƒë„ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
                continue
                
            if "ì¢…ë£Œ" in user_prompt or "ê·¸ë§Œ" in user_prompt:
                print("ğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

        # [B] ë§ˆì´í¬ ìŒì„± ì…ë ¥ ë°©ì‹
        elif choice == 'm':
            audio_file = listen_from_mic()
            
            # ìŒì„± ê°ì§€ ì‹¤íŒ¨ ì‹œ
            if not audio_file:
                print("âš ï¸ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤. ë§ˆì´í¬ì— ê°€ê¹Œì´ ëŒ€ê³  ë§ì”€í•´ ì£¼ì„¸ìš”.")
                continue 
            
            # ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (Whisper)
            user_prompt = transcribe_audio(audio_file)
            
            # íŒŒì¼ì€ ë³€í™˜ í›„ ë°”ë¡œ ì‚­ì œ
            if os.path.exists(audio_file):
                os.remove(audio_file)
            
            # í…ìŠ¤íŠ¸ ë³€í™˜ ì‹¤íŒ¨ ì‹œ
            if not user_prompt or user_prompt.strip() == "":
                print("âš ï¸ ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆê±°ë‚˜ ì•„ë¬´ ë§ì”€ë„ í•˜ì§€ ì•Šìœ¼ì…¨ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.")
                continue

            print(f"\nğŸ—£ï¸ ì¸ì‹ëœ ì§ˆë¬¸: {user_prompt}")
            
            if "ì¢…ë£Œ" in user_prompt or "ê·¸ë§Œ" in user_prompt:
                print("ğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

        # [C] ì˜ëª»ëœ í‚¤ ì…ë ¥ ì²˜ë¦¬
        else:
            print("âš ï¸ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. 't', 'm', 'q' ì¤‘ì—ì„œ í•˜ë‚˜ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
            continue

        print("-" * 30)
        
        # 2. LLMì—ê²Œ ì§ˆë¬¸í•˜ê³  ë‹µë³€ ë°›ê¸° (GPT)
        ai_response = ask_llm(user_prompt)
        
        # 3. LLM ë‹µë³€ ì¶œë ¥ ë° ì¬ì‹œë„ ì¡°ê±´ í™•ì¸
        if ai_response:
            print(f"ğŸ¤– AI ë‹µë³€:\n{ai_response}")
            
            # --- ì¶”ê°€ëœ ë¡œì§: LLMì´ ëª¨ë¥¸ë‹¤ê³  í–ˆì„ ë•Œ ì¬ì‹œë„ ì²˜ë¦¬ ---
            # LLMì˜ ë‹µë³€ì— í¬í•¨ë  ìˆ˜ ìˆëŠ” 'ëª¨ë¥¸ë‹¤'ëŠ” ë‰˜ì•™ìŠ¤ì˜ í‚¤ì›Œë“œë“¤ ë¦¬ìŠ¤íŠ¸
            unknown_keywords = ["ëª¨ë¥´ê² ", "ì•Œ ìˆ˜ ì—†", "ì´í•´í•˜ì§€ ëª»", "ì£„ì†¡í•˜ì§€ë§Œ"]
            
            # ë‹µë³€ ë¬¸ìì—´ ì•ˆì— ìœ„ í‚¤ì›Œë“œê°€ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ê²€ì‚¬
            if any(keyword in ai_response for keyword in unknown_keywords):
                retry_mic = True  # ë‹¤ìŒ ë°˜ë³µì—ì„œ ìë™ìœ¼ë¡œ ë§ˆì´í¬ê°€ ì¼œì§€ë„ë¡ ì„¤ì •
                
        else:
            print("âš ï¸ AIê°€ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
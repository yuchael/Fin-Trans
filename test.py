import requests
import os
import sys
import pandas as pd
import logging
import re
import io  # [ì¶”ê°€] ë¬¸ìì—´ì„ íŒŒì¼ì²˜ëŸ¼ ë‹¤ë£¨ê¸° ìœ„í•´ í•„ìš”
from datetime import datetime
from dotenv import load_dotenv

# utils í´ë”ì˜ handle_sql.pyì—ì„œ í•¨ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
try:
    from utils.handle_sql import execute_query, execute_many
except ImportError:
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from utils.handle_sql import execute_query, execute_many

load_dotenv()

def setup_logging():
    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, "execution.log")

    logging.basicConfig(
        level=logging.INFO,
        format="[%(asctime)s] %(levelname)s: %(message)s",
        handlers=[
            logging.FileHandler(log_file, mode='w', encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )

def fetch_naver_rates():
    """ë„¤ì´ë²„ ê¸ˆìœµ í™˜ìœ¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    url = "https://finance.naver.com/marketindex/exchangeList.naver"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }

    logging.info("ğŸ”„ ë„¤ì´ë²„ ê¸ˆìœµ ë°ì´í„° ìš”ì²­ ì¤‘...")

    try:
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            # 1. ì¸ì½”ë”© ì„¤ì • (HTML ë©”íƒ€íƒœê·¸ì— euc-krë¡œ ë˜ì–´ ìˆìŒ)
            response.encoding = 'cp949'
            
            # 2. ë°ì´í„° íŒŒì‹±
            try:
                # [í•µì‹¬ ìˆ˜ì •] response.textë¥¼ ë°”ë¡œ ë„£ì§€ ì•Šê³  io.StringIOë¡œ ê°ì‹¸ì•¼ 
                # [cite_start]pandasê°€ ì´ë¥¼ 'íŒŒì¼ ê²½ë¡œ'ê°€ ì•„ë‹Œ 'HTML ë‚´ìš©'ìœ¼ë¡œ ì •í™•íˆ ì¸ì‹í•©ë‹ˆë‹¤. [cite: 2]
                html_io = io.StringIO(response.text)
                
                # header=1: ë‘ ë²ˆì§¸ ì¤„(ì‚¬ì‹¤ ë•Œ, íŒŒì‹¤ ë•Œ ë“±)ì„ í—¤ë”ë¡œ ì¸ì‹ ì‹œë„
                dfs = pd.read_html(html_io, header=1)
                
                if dfs:
                    df = dfs[0]
                    # HTML í…Œì´ë¸” êµ¬ì¡° ê¸°ë°˜ ì¸ë±ì‹±:
                    # col 0: í†µí™”ëª…
                    # col 1: ë§¤ë§¤ê¸°ì¤€ìœ¨
                    # col 2,3: í˜„ì°° (ì‚´ë•Œ, íŒ”ë•Œ)
                    # col 4: ì†¡ê¸ˆ ë³´ë‚´ì‹¤ ë•Œ (TTS)
                    # col 5: ì†¡ê¸ˆ ë°›ìœ¼ì‹¤ ë•Œ (TTB)
                    
                    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ìœ„ì¹˜(index)ë¡œ ì¶”ì¶œ
                    target_df = df.iloc[:, [0, 1, 4, 5]].copy()
                    
                    # ì»¬ëŸ¼ëª… ì¬ì„¤ì • (ì§ê´€ì ìœ¼ë¡œ)
                    target_df.columns = ['í†µí™”ëª…', 'ë§¤ë§¤ê¸°ì¤€ìœ¨', 'ì „ì‹ í™˜_ë³´ë‚´ì‹¤ë•Œ', 'ì „ì‹ í™˜_ë°›ìœ¼ì‹¤ë•Œ']
                    
                    now = datetime.now()
                    date_str = now.strftime("%Y%m%d")
                    
                    logging.info(f"âœ… íŒŒì‹± ì„±ê³µ! ë°ì´í„° {len(target_df)}ê±´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                    return target_df, date_str
                else:
                    logging.warning("âš ï¸ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return None, None
            except ImportError:
                logging.error("âŒ 'lxml' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. í„°ë¯¸ë„ì— 'pip install lxml'ì„ ì…ë ¥í•˜ì„¸ìš”.")
                return None, None
            except Exception as parse_error:
                logging.error(f"âš ï¸ íŒŒì‹± ì¤‘ ì—ëŸ¬ ë°œìƒ: {parse_error}")
                return None, None
        else:
            logging.error(f"âŒ ìš”ì²­ ì‹¤íŒ¨ (Status: {response.status_code})")
            return None, None

    except Exception as e:
        logging.error(f"âŒ í¬ë¡¤ë§ ì—ëŸ¬: {e}")
        return None, None

def process_and_save(df, date_str):
    if df is None or df.empty:
        return

    # ì „ì²˜ë¦¬ ì‘ì—…ì„ ìœ„í•´ ë³µì‚¬
    df = df.copy()

    # 1. í†µí™”ëª… ì •ì œ (ê³µë°± ì œê±° ë° í†µí™”ì½”ë“œ ì¶”ì¶œ)
    # HTML ì†ŒìŠ¤ìƒì˜ \n, \t ë“± ê³µë°± ì œê±°
    df['êµ­ê°€/í†µí™”ëª…'] = df['í†µí™”ëª…'].astype(str).str.strip()
    
    # í†µí™”ì½”ë“œ ì¶”ì¶œ (ì˜ˆ: "ë¯¸êµ­ USD" -> "USD", "ì¼ë³¸ JPY (100ì—”)" -> "JPY")
    def extract_code(text):
        match = re.search(r'([A-Z]{3})', text)
        return match.group(1) if match else 'KRW'
    
    df['í†µí™”ì½”ë“œ'] = df['êµ­ê°€/í†µí™”ëª…'].apply(extract_code)

    # 2. ìˆ«ì ë°ì´í„° ì „ì²˜ë¦¬ (ì½¤ë§ˆ ì œê±°, N/A ì²˜ë¦¬)
    target_cols = ['ë§¤ë§¤ê¸°ì¤€ìœ¨', 'ì „ì‹ í™˜_ë³´ë‚´ì‹¤ë•Œ', 'ì „ì‹ í™˜_ë°›ìœ¼ì‹¤ë•Œ']
    
    for col in target_cols:
        # ë¬¸ìì—´ ë³€í™˜ -> ì½¤ë§ˆ ì œê±° -> ìˆ«ìë¡œ ë³€í™˜ (ì‹¤íŒ¨ì‹œ 0)
        df[col] = df[col].astype(str).str.replace(",", "").str.strip()
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    # 3. ê¸°ì¤€ì¼ì ì¶”ê°€
    df['ê¸°ì¤€ì¼ì'] = date_str

    # 4. ì €ì¥í•  ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
    final_columns = ['ê¸°ì¤€ì¼ì', 'í†µí™”ì½”ë“œ', 'êµ­ê°€/í†µí™”ëª…', 'ë§¤ë§¤ê¸°ì¤€ìœ¨', 'ì „ì‹ í™˜_ë°›ìœ¼ì‹¤ë•Œ', 'ì „ì‹ í™˜_ë³´ë‚´ì‹¤ë•Œ']
    df = df[final_columns]

    # --- CSV ì €ì¥ ---
    save_dir = "data"
    os.makedirs(save_dir, exist_ok=True)
    csv_filename = os.path.join(save_dir, "exchange_rates_naver.csv")
    df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
    logging.info(f"ğŸ’¾ CSV ì €ì¥ ì™„ë£Œ: {csv_filename}")
    
    # --- MySQL ì €ì¥ ---
    save_to_mysql(df, date_str)

def save_to_mysql(df, date_str):
    formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"

    try:
        logging.info(f"ğŸ”Œ MySQL ì €ì¥ ì‹œì‘ (ê¸°ì¤€ì¼: {formatted_date})")
        
        # 1. ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
        delete_sql = "DELETE FROM exchange_rates WHERE reference_date = %s"
        execute_query(delete_sql, (formatted_date,))
        
        # 2. ìƒˆ ë°ì´í„° ì‚½ì…
        insert_sql = """
        INSERT INTO exchange_rates 
        (reference_date, currency_code, currency_name, deal_bas_r, ttb, tts)
        VALUES (%s, %s, %s, %s, %s, %s)
        """
        
        data_list = []
        for _, row in df.iterrows():
            data_list.append((
                formatted_date,
                row['í†µí™”ì½”ë“œ'],
                row['êµ­ê°€/í†µí™”ëª…'],
                row['ë§¤ë§¤ê¸°ì¤€ìœ¨'],
                row['ì „ì‹ í™˜_ë°›ìœ¼ì‹¤ë•Œ'],
                row['ì „ì‹ í™˜_ë³´ë‚´ì‹¤ë•Œ']
            ))
        
        inserted_count = execute_many(insert_sql, data_list)
        logging.info(f"ğŸ“¥ DB ì €ì¥ ì™„ë£Œ: {inserted_count}ê±´")

    except Exception as e:
        logging.error(f"âŒ DB ì €ì¥ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    setup_logging()
    
    # SSL ê²½ê³  ë¬´ì‹œ (í•„ìš”ì‹œ)
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

    logging.info("ğŸš€ í™˜ìœ¨ ì •ë³´ ì—…ë°ì´íŠ¸ ì‹œì‘...")
    
    rates_data, rates_date = fetch_naver_rates()
    
    if rates_data is not None:
        process_and_save(rates_data, rates_date)
        logging.info("ğŸ‰ ì‘ì—… ì™„ë£Œ!")
    else:
        logging.warning("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
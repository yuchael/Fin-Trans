import os
import json
from pathlib import Path
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ì „ë¬¸ê°€ ëª¨ë“ˆ ì„í¬íŠ¸
from rag_agent.sql_agent import get_sql_answer
from rag_agent.finrag_agent import get_rag_answer

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# LLM ì„¤ì •
llm = ChatOpenAI(model="gpt-5-mini")

# [ë³€ê²½] ë©”ëª¨ë¦¬ ëŒ€ì‹  ì§ì ‘ ê´€ë¦¬í•  ì „ì—­ ë³€ìˆ˜ (ì„ì‹œ)
# ì£¼ì˜: ì‹¤ì œ ë°°í¬ ì‹œì—ëŠ” DBë‚˜ Session Stateë¡œ ê´€ë¦¬í•´ì•¼ ì‚¬ìš©ì ê°„ ì„ì´ì§€ ì•ŠìŠµë‹ˆë‹¤.
GLOBAL_CHAT_CONTEXT = {"summary": ""}

# ---------------------------------------------------------
# [ì„¤ì •] í”„ë¡¬í”„íŠ¸ ê²½ë¡œ ì„¤ì • ë° ë¡œë”© í•¨ìˆ˜
# ---------------------------------------------------------
CURRENT_DIR = Path(__file__).resolve().parent
PROMPT_DIR = CURRENT_DIR / "prompt" / "main"

def read_prompt(filename: str) -> str:
    """MD íŒŒì¼ì„ ì½ì–´ì„œ ë¬¸ìì—´ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    file_path = PROMPT_DIR / filename
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        print(f"âŒ [Error] í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return ""

# ---------------------------------------------------------
# [Step 1] ì–¸ì–´ ê°ì§€ ë° í•œêµ­ì–´ ë²ˆì—­ ì²´ì¸
# ---------------------------------------------------------
translation_template = read_prompt("main_01_translation.md")
translation_prompt = PromptTemplate.from_template(translation_template)
translation_chain = translation_prompt | llm | StrOutputParser()

# ---------------------------------------------------------
# [Step 2] ë¬¸ë§¥ ë³´ì •(Refinement) ì²´ì¸
# ---------------------------------------------------------
refinement_template = read_prompt("main_02_refinement.md")
refinement_prompt = PromptTemplate.from_template(refinement_template)
refinement_chain = refinement_prompt | llm | StrOutputParser()

# ---------------------------------------------------------
# [Step 3] ì˜ë„ ë¶„ë¥˜ ì²´ì¸ (Router)
# ---------------------------------------------------------
router_template = read_prompt("main_03_router.md")
router_prompt = PromptTemplate.from_template(router_template)
router_chain = router_prompt | llm | StrOutputParser()

# ---------------------------------------------------------
# [Step 4-C] ì¼ìƒ ëŒ€í™” (System Prompt) ì²˜ë¦¬ ì²´ì¸
# ---------------------------------------------------------
system_prompt_template = read_prompt("main_04_system.md")
system_prompt_chain = PromptTemplate.from_template(system_prompt_template) | llm | StrOutputParser()

# ---------------------------------------------------------
# [Step 5] ìµœì¢… ë‹µë³€ ì—­ë²ˆì—­ ì²´ì¸
# ---------------------------------------------------------
re_translation_template = read_prompt("main_05_re_translation.md")
re_translation_prompt = PromptTemplate.from_template(re_translation_template)
re_translation_chain = re_translation_prompt | llm | StrOutputParser()

# ---------------------------------------------------------
# [NEW] ëŒ€í™” ìš”ì•½ ì²´ì¸ (ë©”ëª¨ë¦¬ ëŒ€ì²´ìš©)
# ---------------------------------------------------------
summarizer_template = read_prompt("main_06_summarizer.md")
summarizer_prompt = PromptTemplate.from_template(summarizer_template)
summarizer_chain = summarizer_prompt | llm | StrOutputParser()

def update_summary(current_summary, user_input, ai_output):
    """LLMì„ ì´ìš©í•´ ëŒ€í™” ìš”ì•½ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” í•¨ìˆ˜"""
    try:
        new_summary = summarizer_chain.invoke({
            "current_summary": current_summary,
            "user_input": user_input,
            "ai_output": ai_output
        }).strip()
        return new_summary
    except Exception as e:
        print(f"âš ï¸ ìš”ì•½ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return current_summary

# ---------------------------------------------------------
# ë©”ì¸ ì—ì´ì „íŠ¸ ì‹¤í–‰ í•¨ìˆ˜
# ---------------------------------------------------------
def run_fintech_agent(question):
    print(f"\n[User Input]: {question}")
    
    # --- Step 1: ì–¸ì–´ ê°ì§€ ë° í•œêµ­ì–´ ë²ˆì—­ ---
    try:
        trans_result_str = translation_chain.invoke({"question": question}).strip()
        trans_result_str = trans_result_str.replace("```json", "").replace("```", "")
        trans_result = json.loads(trans_result_str)
        
        source_lang = trans_result.get("source_language", "Korean")
        korean_query = trans_result.get("korean_query", question)
        print(f"ğŸŒ [Step 1] ê°ì§€ ì–¸ì–´: {source_lang} -> ë³€í™˜: {korean_query}")
        
    except Exception as e:
        print(f"âš ï¸ ë²ˆì—­ ì˜¤ë¥˜: {e}")
        source_lang = "Korean"
        korean_query = question

    # --- Step 2: ë©”ëª¨ë¦¬ë¥¼ í™œìš©í•œ ì§ˆë¬¸ êµ¬ì²´í™” (Refinement) ---
    # [ë³€ê²½] ë©”ëª¨ë¦¬ ê°ì²´ ëŒ€ì‹  ì „ì—­ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´
    current_history = GLOBAL_CHAT_CONTEXT["summary"]
    refined_query = korean_query
    
    if current_history:
        print(f"ğŸ§  [Memory Summary]: {current_history}")
        refined_query = refinement_chain.invoke({
            "history": current_history,
            "question": korean_query
        }).strip()
        
        if refined_query != korean_query:
            print(f"âœ¨ [Step 2] ì§ˆë¬¸ ë³´ì •: '{korean_query}' -> '{refined_query}'")
    else:
        print("âœ¨ [Step 2] ë³´ì • ìƒëµ (ì´ì „ ëŒ€í™” ì—†ìŒ)")

    # --- Step 3: ì˜ë„ íŒŒì•… (Router) ---
    category = router_chain.invoke({"question": refined_query}).strip()
    category = category.replace("'", "").replace('"', "").replace(".", "")
    print(f"ğŸ•µï¸ [Step 3] ì˜ë„ ë¶„ë¥˜: [{category}]")
    
    korean_answer = ""
    
    # --- Step 4: ì „ë¬¸ê°€ í˜¸ì¶œ (Agent Execution) ---
    if category == "DATABASE":
        print("\n=== ğŸ¦ SQL Agent í˜¸ì¶œ ===")
        korean_answer = get_sql_answer(refined_query)
        print("=== ğŸ¦ SQL Agent ì¢…ë£Œ ===\n")
        
    elif category == "KNOWLEDGE":
        print("\n=== ğŸ“ FinRAG Agent í˜¸ì¶œ ===")
        korean_answer = get_rag_answer(refined_query, original_query=question)
        print("=== ğŸ“ FinRAG Agent ì¢…ë£Œ ===\n")
        
    elif category == "GENERAL":
        print("\n=== ğŸ’¬ System Prompt í˜¸ì¶œ ===")
        korean_answer = system_prompt_chain.invoke({"question": korean_query})
        print("=== ğŸ’¬ System Prompt ì¢…ë£Œ ===\n")
        
    else:
        korean_answer = "ì£„ì†¡í•´ìš”, ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        print(f"âŒ [Exception] ì²˜ë¦¬ ë¶ˆê°€ ì¹´í…Œê³ ë¦¬: {category}")

    # --- [NEW] ëŒ€í™” ë‚´ìš© ìš”ì•½ ì—…ë°ì´íŠ¸ (ë©”ëª¨ë¦¬ ì €ì¥ ëŒ€ì²´) ---
    print("ğŸ“ [Memory] ëŒ€í™” ìš”ì•½ ì—…ë°ì´íŠ¸ ì¤‘...")
    updated_summary = update_summary(current_history, refined_query, korean_answer)
    GLOBAL_CHAT_CONTEXT["summary"] = updated_summary
    print(f"âœ… [Memory Updated]: {updated_summary[:50]}...")

    # --- Step 5: ìµœì¢… ë‹µë³€ ì—­ë²ˆì—­ ---
    if "Korean" not in source_lang and "í•œêµ­ì–´" not in source_lang:
        print(f"ğŸ”„ [Step 5] ë‹µë³€ ì—­ë²ˆì—­ ì¤‘...")
        foreign_answer = re_translation_chain.invoke({
            "target_language": source_lang, 
            "korean_answer": korean_answer
        })
        final_answer = f"""{foreign_answer}\n\n=========================================\nğŸ“¢ [í•œêµ­ì–´ ë²ˆì—­ë³¸ / Demo Translation]\n{korean_answer}\n========================================="""
    else:
        final_answer = korean_answer

    print(f"ğŸ”„ [Step 6] ìµœì¢… ë‹µë³€ ì™„ë£Œ!")

    return final_answer
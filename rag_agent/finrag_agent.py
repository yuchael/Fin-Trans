import os
import json
import numpy as np
import pandas as pd
from sqlalchemy import create_engine
from openai import OpenAI
from dotenv import load_dotenv

# 1. í™˜ê²½ ì„¤ì •
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

DB_USER = os.getenv("DB_USER", "root")
DB_PASSWORD = os.getenv("DB_PASSWORD", "")
DB_HOST = os.getenv("DB_HOST", "localhost")
DB_PORT = os.getenv("DB_PORT", "3306")
DB_NAME = os.getenv("DB_NAME", "fintech_agent")

# ì „ì—­ ë³€ìˆ˜ ì„ ì–¸ (ë°ì´í„°ë¥¼ í•œ ë²ˆë§Œ ë¡œë”©í•˜ê¸° ìœ„í•¨)
df = None
embedding_matrix = None

def load_knowledge_base():
    """DBì—ì„œ ê¸ˆìœµ ì§€ì‹ì„ ë¡œë“œí•˜ê³  ë²¡í„° í–‰ë ¬ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    global df, embedding_matrix
    if df is not None:
        return # ì´ë¯¸ ë¡œë”©ë˜ì—ˆë‹¤ë©´ ìŠ¤í‚µ

    print("â³ [RAG] ê¸ˆìœµ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤...")
    db_url = f"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}?charset=utf8mb4"
    engine = create_engine(db_url)

    df = pd.read_sql("SELECT word, definition, embedding FROM terms", engine)
    df['embedding'] = df['embedding'].apply(json.loads)
    embedding_matrix = np.vstack(df['embedding'].values)
    print(f"âœ… ë¡œë”© ì™„ë£Œ! (ì´ {len(df)}ê°œ ìš©ì–´)")

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
def get_embedding(text):
    return client.embeddings.create(input=[text], model="text-embedding-3-small").data[0].embedding

def search_docs(query_text, top_k=3):
    query_vec = get_embedding(query_text)
    similarities = np.dot(embedding_matrix, query_vec) / (
        np.linalg.norm(embedding_matrix, axis=1) * np.linalg.norm(query_vec)
    )
    df['similarity'] = similarities
    return df.sort_values('similarity', ascending=False).head(top_k)

def translate_query_to_korean(user_query):
    """ì™¸êµ­ì–´ ì§ˆë¬¸ì„ í•œêµ­ì–´ ê²€ìƒ‰ í‚¤ì›Œë“œë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": """
             You are a sophisticated translation assistant for a Korean Financial Terminology Search Engine.
             Your goal is to convert the user's query into the most appropriate Korean financial keyword.
             Output ONLY the Korean keyword(s).
             """},
            {"role": "user", "content": user_query}
        ],
        temperature=0
    )
    return response.choices[0].message.content.strip()

# ğŸ”¥ ì™¸ë¶€(main_agent.py)ì—ì„œ í˜¸ì¶œí•  ê³µì‹ í•¨ìˆ˜
def get_rag_answer(user_query):
    # í˜¸ì¶œ ì‹œì ì— ë°ì´í„°ê°€ ë¡œë“œ ì•ˆ ë˜ì–´ ìˆë‹¤ë©´ ë¡œë“œ
    if df is None:
        load_knowledge_base()

    # [ìˆ˜ì • 1] ë²ˆì—­ ë‹¨ê³„ ì‚­ì œ (ì´ë¯¸ main_agentì—ì„œ í•œêµ­ì–´ë¡œ ì¤Œ)
    # korean_search_term = translate_query_to_korean(user_query) <- ì‚­ì œ
    korean_search_term = user_query # ë°›ì€ ê·¸ëŒ€ë¡œ ê²€ìƒ‰ì–´ë¡œ ì‚¬ìš©

    # 2. ê²€ìƒ‰ ë‹¨ê³„
    relevant_docs = search_docs(korean_search_term)
    
    # ìœ ì‚¬ë„ ì²´í¬ (ê´€ë ¨ì„± ë‚®ì€ ê²½ìš° ë°©ì–´)
    if relevant_docs.iloc[0]['similarity'] < 0.30:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê¸ˆìœµ ì§€ì‹ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context_text = ""
    for idx, row in relevant_docs.iterrows():
        context_text += f"Term: {row['word']}\nDefinition: {row['definition']}\n\n"

    # [ìˆ˜ì • 2] ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë³€ê²½ (í•œêµ­ì–´ ë‹µë³€ ê°•ì œ)
    system_prompt = f"""
    You are a helpful Financial Expert AI. 
    Explain the financial concept based on the [Context].
    
    [Rules]
    1. Answer ONLY in Korean. (ë¬´ì¡°ê±´ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”)
    2. Explain clearly and easily.
    
    [Context]
    {context_text}
    """

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_query}
        ],
        temperature=0
    )

    return response.choices[0].message.content.strip()

# ë‹¨ë… í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    # ë‹¨ë… ì‹¤í–‰ ì‹œì—ë§Œ ë¡œë”© ë° ë£¨í”„ ê°€ë™
    load_knowledge_base()
    while True:
        inp = input("\nQ (exit to quit): ")
        if inp.lower() in ['exit', 'quit']: break
        print(f"\nA: {get_rag_answer(inp)}")
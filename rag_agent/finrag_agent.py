import os
from pathlib import Path
from dotenv import load_dotenv

# LangChain ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# [NEW] ì›¹ ê²€ìƒ‰ ëª¨ë“ˆ ì„í¬íŠ¸
from rag_agent.web_search_rag import WebSearchRAG

# 1. í™˜ê²½ ì„¤ì •
load_dotenv()

# ê²½ë¡œ ì„¤ì •
CURRENT_FILE_PATH = Path(__file__).resolve() 
PROJECT_ROOT = CURRENT_FILE_PATH.parent.parent 
PROMPT_DIR = CURRENT_FILE_PATH.parent / "prompt" / "finrag"

# ChromaDB ë°ì´í„° ê²½ë¡œ
CHROMA_DB_PATH = PROJECT_ROOT / "data" / "financial_terms"
COLLECTION_NAME = "financial_terms"

# [ì„¤ì •] ê²€ìƒ‰ í’ˆì§ˆì„ ìœ„í•œ ì„ê³„ê°’ (Threshold)
# L2 Distance ê¸°ì¤€: 0.6ë³´ë‹¤ í¬ë©´ ê´€ë ¨ ì—†ëŠ” ë¬¸ì„œë¡œ íŒë‹¨
SIMILARITY_THRESHOLD = 0.6

# [ì„¤ì •] ì›¹ ê²€ìƒ‰ì„ ê°•ì œí•  í‚¤ì›Œë“œ ëª©ë¡
WEB_SEARCH_KEYWORDS = ["í˜„ì¬", "ìµœì‹ ", "ì˜¤ëŠ˜", "ì£¼ê°€", "ì‹œì„¸", "ë‰´ìŠ¤", "ì „ë§", "ë‚ ì”¨", "ê²€ìƒ‰í•´ì¤˜", "ì–¼ë§ˆì•¼"]

# ì „ì—­ ë³€ìˆ˜
vectorstore = None
llm = ChatOpenAI(model="gpt-5-mini")
web_rag = WebSearchRAG() # ì›¹ ê²€ìƒ‰ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

def load_prompt(filename: str) -> str:
    """MD íŒŒì¼ì„ ì½ì–´ì„œ ë¬¸ìì—´ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    file_path = PROMPT_DIR / filename
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        print(f"âŒ [Error] í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return "{context}\n{question}"

def load_knowledge_base():
    """ChromaDB ì—°ê²° ì„¤ì •"""
    global vectorstore
    if vectorstore is not None: return

    print("â³ [RAG] ChromaDB ì—°ê²° ì¤‘...")
    try:
        embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
        
        vectorstore = Chroma(
            persist_directory=str(CHROMA_DB_PATH),
            embedding_function=embeddings,
            collection_name=COLLECTION_NAME,
            collection_metadata={"hnsw:space": "l2"} 
        )
        print(f"âœ… ChromaDB ì—°ê²° ì™„ë£Œ (Metirc: L2, ê²½ë¡œ: {CHROMA_DB_PATH})")
        
    except Exception as e:
        print(f"âŒ ChromaDB ì—°ê²° ì˜¤ë¥˜: {e}")
        vectorstore = None

def format_web_result(web_result, original_query, translated_query):
    """ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ì¡´ RAG ë‹µë³€ í¬ë§·ìœ¼ë¡œ ë³€í™˜"""
    citations = [f"- **{src['title']}**: {src['url']}" for src in web_result.get('sources', [])]
    citation_text = "\n".join(citations) if citations else "- ì¶œì²˜ ì •ë³´ ì—†ìŒ"

    return f"""
### ğŸŒ ì§ˆë¬¸
- **Original**: {original_query if original_query else translated_query}
- **Translated**: {translated_query}

### ğŸŒ FinBotì˜ ì›¹ ê²€ìƒ‰ ë‹µë³€
{web_result['answer']}

---
### ğŸ“š ì°¸ê³  ì›¹ì‚¬ì´íŠ¸
{citation_text}
"""

def get_rag_answer(korean_query, original_query=None):
    if vectorstore is None: load_knowledge_base()

    # ---------------------------------------------------------
    # [Logic 1] ì‹¤ì‹œê°„ì„±/ê²€ìƒ‰ ì˜ë„ í‚¤ì›Œë“œ ì²´í¬ -> ì¦‰ì‹œ ì›¹ ê²€ìƒ‰
    # ---------------------------------------------------------
    if any(keyword in korean_query for keyword in WEB_SEARCH_KEYWORDS):
        print(f"ğŸš€ [FinRAG] ì‹¤ì‹œê°„ í‚¤ì›Œë“œ ê°ì§€ -> ì›¹ ê²€ìƒ‰ ì „í™˜: '{korean_query}'")
        web_result = web_rag.web_search(korean_query)
        return format_web_result(web_result, original_query, korean_query)

    # ---------------------------------------------------------
    # [Logic 2] ChromaDB ê²€ìƒ‰ ìˆ˜í–‰
    # ---------------------------------------------------------
    relevant_docs = []
    if vectorstore:
        try:
            results = vectorstore.similarity_search_with_score(korean_query, k=5)
            print(f"ğŸ” [Search] '{korean_query}' DB ê²€ìƒ‰ ìˆ˜í–‰")
            
            for doc, score in results:
                # L2 DistanceëŠ” 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬í•¨ (Threshold ì´í•˜ë§Œ ì±„íƒ)
                if score <= SIMILARITY_THRESHOLD:
                    relevant_docs.append((doc, score))
                    print(f"   âœ… ì±„íƒ: {doc.metadata.get('word')} (ê±°ë¦¬: {score:.4f})")
                else:
                    print(f"   âŒ ì œì™¸: {doc.metadata.get('word')} (ê±°ë¦¬: {score:.4f} > {SIMILARITY_THRESHOLD})")
            
            # ìƒìœ„ 3ê°œë§Œ ì‚¬ìš©
            relevant_docs = relevant_docs[:3]
        except Exception as e:
            print(f"âš ï¸ DB ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            relevant_docs = []

    # ---------------------------------------------------------
    # [Logic 3] Fallback: DBì— ì •ë³´ê°€ ì—†ì„ ê²½ìš° -> ì›¹ ê²€ìƒ‰ ìë™ ì „í™˜
    # ---------------------------------------------------------
    if not relevant_docs:
        print(f"âš ï¸ [FinRAG] ë‚´ë¶€ DBì— ê´€ë ¨ ì •ë³´ ì—†ìŒ (ìœ íš¨ ë¬¸ì„œ 0ê°œ) -> ì›¹ ê²€ìƒ‰ ìë™ ì „í™˜")
        web_result = web_rag.web_search(korean_query)
        return format_web_result(web_result, original_query, korean_query)

    # ---------------------------------------------------------
    # [Logic 4] DB ê¸°ë°˜ ë‹µë³€ ìƒì„± (ê¸°ì¡´ RAG ë¡œì§)
    # ---------------------------------------------------------
    context_text = ""
    citations = []
    
    for doc, score in relevant_docs:
        word = doc.metadata.get("word", "Term")
        raw_content = doc.page_content
        definition = raw_content.split(":", 1)[1].strip() if ":" in raw_content else raw_content
        
        context_text += f"- **{word}**: {definition}\n"
        citations.append(f"- **{word}**: {definition[:60]}... (ê±°ë¦¬: {score:.4f})")

    # í”„ë¡¬í”„íŠ¸ ë¡œë”© ë° ì²´ì¸ ìƒì„±
    system_template = load_prompt("finrag_01_system.md")
    rag_prompt = PromptTemplate.from_template(system_template)
    rag_chain = rag_prompt | llm | StrOutputParser()

    try:
        ai_answer = rag_chain.invoke({
            "context": context_text,
            "question": korean_query
        })
    except Exception as e:
        ai_answer = f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ({e})"

    # ìµœì¢… ì¶œë ¥ í¬ë§·íŒ…
    final_output = f"""
### ğŸŒ ì§ˆë¬¸
- **Original**: {original_query if original_query else korean_query}
- **Translated**: {korean_query}

### ğŸ’¡ FinBotì˜ ë‹µë³€
{ai_answer}

---
### ğŸ“š ë‚´ë¶€ ì°¸ê³  ë¬¸í—Œ
{chr(10).join(citations)}
    """
    
    return final_output

if __name__ == "__main__":
    load_knowledge_base()
    # Test 1: DBì— ìˆëŠ” ë‚´ìš©
    print(get_rag_answer("ê¸ˆë¦¬ê°€ ë­ì•¼?"))
    print("-" * 50)
    # Test 2: ì‹¤ì‹œê°„ ì •ë³´ (í‚¤ì›Œë“œ íŠ¸ë¦¬ê±°)
    print(get_rag_answer("í˜„ì¬ ì‚¼ì„±ì „ì ì£¼ê°€ ì•Œë ¤ì¤˜"))
    print("-" * 50)
    # Test 3: DBì— ì—†ëŠ” ë‚´ìš© (Fallback íŠ¸ë¦¬ê±°) -> ì˜ˆë¥¼ ë“¤ì–´ ì—‰ëš±í•œ ì§ˆë¬¸
    print(get_rag_answer("ì•„ì´ìœ  ìµœì‹  ì•¨ë²” ë­ì•¼?"))